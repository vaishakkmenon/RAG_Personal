# ============================================================================
# Personal RAG System - Docker Compose Configuration
# ============================================================================
# Services:
#   - api:    FastAPI backend with ChromaDB
#   - redis:  Session storage and caching
#   - test:   Testing environment
# ============================================================================

name: personal-rag-system

services:
  # ==========================================================================
  # FastAPI API Service - Main application
  # ==========================================================================
  api:
    build:
      context: .
      target: runtime
      args:
        - BUILDKIT_INLINE_CACHE=1

    secrets:
      - api_keys
      - groq_api_key
      - postgres_password
      - redis_password
    image: personal-rag-system:latest
    container_name: rag_api
    hostname: api

    # Port mapping: host:container
    # ports:
    #   - "${API_PORT:-8000}:8000"  # Disabled: Access via Caddy on 80/443 only

    # Environment variables (with sensible defaults)
    environment:
      # ============ Application Settings ============
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - PYTHONUNBUFFERED=1
      - WATCHFILES_FORCE_POLLING=1

      # ============ LLM Provider Configuration ============
      # Primary: Groq (cloud API)
      - LLM_PROVIDER=${LLM_PROVIDER:-groq}
      # Secrets Injection
      - API_KEYS_FILE=/run/secrets/api_keys
      - LLM_GROQ_API_KEY_FILE=/run/secrets/groq_api_key
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - REDIS_PASSWORD_FILE=/run/secrets/redis_password
      # Fallbacks (for simple dev setups)
      - LLM_GROQ_API_KEY=${LLM_GROQ_API_KEY:-}
      - LLM_GROQ_MODEL=${LLM_GROQ_MODEL:-llama-3.1-70b-versatile}

      # LLM generation parameters
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.1}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-1000}

      # ============ Session Management (Redis) ============
      - SESSION_STORAGE_BACKEND=${SESSION_STORAGE_BACKEND:-redis}
      - SESSION_REDIS_URL=redis://:${REDIS_PASSWORD:-devpassword123}@redis:6379/0
      - SESSION_MAX_TOTAL_SESSIONS=${SESSION_MAX_TOTAL_SESSIONS:-1000}
      - SESSION_MAX_SESSIONS_PER_IP=${SESSION_MAX_SESSIONS_PER_IP:-100}  # Increased for testing
      - SESSION_QUERIES_PER_HOUR=${SESSION_QUERIES_PER_HOUR:-1000}  # Increased for testing
      - SESSION_TTL_SECONDS=${SESSION_TTL_SECONDS:-21600}
      - SESSION_MAX_HISTORY_TOKENS=${SESSION_MAX_HISTORY_TOKENS:-250}
      - SESSION_MAX_HISTORY_TURNS=${SESSION_MAX_HISTORY_TURNS:-5}

      # ============ Database Configuration ============
      # Force internal port to 5432 (standard) even if host uses 5433
      - POSTGRES_PORT=5432

      # ============ Security ============
      - SESSION_REQUIRE_HTTPS=true  # Now handled by Caddy

      # ============ Query Rewriting (Disabled - causes regressions) ============
      - QUERY_REWRITER_ENABLED=${QUERY_REWRITER_ENABLED:-false}

      # ============ HuggingFace Cache (redirect to writable /tmp) ============
      - HF_HOME=/tmp/huggingface
      - HUGGINGFACE_HUB_CACHE=/tmp/huggingface

      # ============ Uvicorn Server Config ============
      - UVICORN_WORKERS=${UVICORN_WORKERS:-2}
      - UVICORN_LOG_LEVEL=${LOG_LEVEL:-info}

    # Load additional env vars from .env file
    env_file:
      - .env

    # Volume mounts
    volumes:
      # Application code (for development hot-reload)
      - ./app:/workspace/app:ro

      # Scripts for evaluation and utilities
      - ./scripts:/workspace/scripts:ro

      # Environment file (read-only)
      - ./.env:/workspace/.env:ro

      # Configuration files
      - ./config:/workspace/config:ro

      # Data directories
      - ./data/chroma:/workspace/data/chroma
      - ./data/docs:/workspace/data/docs
      - ./data/mds:/workspace/data/mds:ro
      - ./data/eval:/workspace/data/eval
      - ./data/analytics:/workspace/data/analytics

    # Service dependencies (with health checks)
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy

    # Security hardening
    security_opt:
      - no-new-privileges:true

    read_only: true

    # Drop all capabilities (principle of least privilege)
    cap_drop:
      - ALL

    # Writable /tmp for runtime files and model cache
    tmpfs:
      - /tmp:noexec,nosuid,nodev,size=512m

    # Run as non-root user (nonroot:nonroot = 65532:65532)
    user: "65532:65532"

    # Use entrypoint script for initialization, then start uvicorn
    entrypoint: ["/bin/bash", "/workspace/scripts/docker-entrypoint.sh"]
    command:
      - /opt/venv/bin/python
      - -m
      - uvicorn
      - app.main:app
      - --host
      - "0.0.0.0"
      - --port
      - "8000"
      - --workers
      - "${UVICORN_WORKERS:-2}"
      - --log-level
      - "${LOG_LEVEL:-info}"
      # Trust proxy headers (X-Forwarded-Proto) from Caddy
      - --proxy-headers
      - --forwarded-allow-ips
      - "*"

    # Health check (critical for depends_on conditions)
    healthcheck:
      test:
        - CMD
        - /opt/venv/bin/python
        - -c
        - "import socket; s=socket.socket(); s.settimeout(5); s.connect(('127.0.0.1', 8000)); s.close(); print('âœ… API healthy')"
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Restart policy
    restart: unless-stopped

    # Resource limits (MATCHING CONTABO VPS SPECS)
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 2G

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=api"
    networks:
      - frontend
      - backend

  # ==========================================================================
  # Caddy Service - URL/HTTPS Reverse Proxy
  # ==========================================================================
  caddy:
    image: caddy:2-alpine
    container_name: rag_caddy
    hostname: caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      api:
        condition: service_healthy
    networks:
      - frontend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================================================
  # PostgreSQL Service - Feedback and structured data
  # ==========================================================================
  postgres:
    image: postgres:15-alpine
    container_name: rag_postgres
    hostname: postgres

    environment:
      POSTGRES_USER: ${POSTGRES_USER:-rag_user}
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
      POSTGRES_DB: ${POSTGRES_DB:-rag_db}

    secrets:
      - postgres_password

    ports:
      # Bind to localhost only to prevent external access even if UFW fails
      # Using 5433 externally to avoid conflict with local Postgres (PID 8660)
      - "127.0.0.1:${POSTGRES_HOST_PORT:-5433}:5432"
    networks:
      - backend

    volumes:
      - postgres_data:/var/lib/postgresql/data

    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-rag_user} -d ${POSTGRES_DB:-rag_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

    restart: unless-stopped

    security_opt:
      - no-new-privileges:true

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=postgres"

  # ==========================================================================
  # Redis Service - Session storage and caching
  # ==========================================================================
  redis:
    image: redis:7-alpine
    container_name: rag_redis
    hostname: redis

    # Redis server configuration
    command:
      - redis-server
      - --appendonly yes                    # Enable AOF persistence
      - --requirepass ${REDIS_PASSWORD:-devpassword123}  # Require encryption
      - --appendfsync everysec              # Fsync every second (balanced)
      - --maxmemory 256mb                   # Memory limit
      - --maxmemory-policy allkeys-lru      # Eviction policy
      - --save 60 1                         # RDB snapshot: every 60s if 1 key changed
      - --loglevel notice                   # Logging level
      - --tcp-backlog 511                   # Connection queue size
      - --timeout 300                       # Close idle connections after 5min
      - --tcp-keepalive 300                 # TCP keepalive

    ports:
      # Bind to localhost only
      - "127.0.0.1:${REDIS_PORT:-6379}:6379"
    networks:
      - backend

    volumes:
      - redis_data:/data

    # Health check (critical for API service dependency)
    healthcheck:
      test:
        - CMD
        - redis-cli
        - -a
        - ${REDIS_PASSWORD:-devpassword123}
        - --raw
        - incr
        - ping
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

    # Security hardening
    security_opt:
      - no-new-privileges:true

    # Restart policy
    restart: unless-stopped

    # Resource limits (optional)
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '0.5'
    #       memory: 512M
    #     reservations:
    #       cpus: '0.25'
    #       memory: 256M

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=redis"

  # ==========================================================================
  # Redis Exporter - Prometheus metrics for Redis
  # ==========================================================================
  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: rag_redis_exporter
    hostname: redis-exporter
    environment:
      - REDIS_ADDR=redis:6379
      - REDIS_PASSWORD=${REDIS_PASSWORD:-devpassword123}
    ports:
      - "127.0.0.1:9121:9121"
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - backend
      - frontend  # Allow Prometheus to scrape
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================================================
  # PostgreSQL Exporter - Prometheus metrics for PostgreSQL
  # ==========================================================================
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: rag_postgres_exporter
    hostname: postgres-exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://${POSTGRES_USER:-rag_user}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-rag_db}?sslmode=disable
    ports:
      - "127.0.0.1:9187:9187"
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - backend
      - frontend  # Allow Prometheus to scrape
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================================================
  # Backup Service - Automated Nightly Backups
  # ==========================================================================
  backup:
    image: postgres:15-alpine
    container_name: rag_backup
    hostname: backup
    restart: unless-stopped

    # Run the backup script every 24 hours (86400 seconds)
    command: >
      sh -c "while true; do
        echo 'Running daily backup...';
        /scripts/backup.sh;
        echo 'Sleeping for 24 hours...';
        sleep 86400;
      done"

    volumes:
      - ./backups:/backups
      - ./scripts:/scripts:ro
      - redis_data:/var/lib/redis:ro      # Read-only access to Redis data
      - ./data/chroma:/chroma_data:ro     # Read-only access to Chroma data

    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - BACKUP_DIR=/backups

    secrets:
      - postgres_password

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

    networks:
      - backend

  # ==========================================================================
  # Prometheus Service - Metrics collection and alerting
  # ==========================================================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: rag_prometheus
    hostname: prometheus

    ports:
      - "9090:9090"

    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_data:/prometheus

    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=7d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'

    depends_on:
      api:
        condition: service_healthy
    networks:
      - backend
      - frontend  # Allow localhost access

    restart: unless-stopped

    # Security hardening
    security_opt:
      - no-new-privileges:true

    # Prometheus runs as nobody (65534) by default
    user: "65534:65534"

    # Health check
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=prometheus,env=development"

  # ==========================================================================
  # Alertmanager Service - Alert notifications
  # ==========================================================================
  alertmanager:
    image: prom/alertmanager:v0.26.0
    container_name: rag_alertmanager
    hostname: alertmanager
    ports:
      - "127.0.0.1:9093:9093"
    volumes:
      - ./monitoring/prometheus/alertmanager.yml.template:/etc/alertmanager/alertmanager.yml.template:ro
      - alertmanager_data:/alertmanager
    # Use sed to substitute environment variables into the config template
    # (Alertmanager doesn't support env var substitution natively)
    entrypoint:
      - /bin/sh
      - -c
      - |
        sed -e "s|\$${SMTP_FROM}|$$SMTP_FROM|g" \
            -e "s|\$${SMTP_USERNAME}|$$SMTP_USERNAME|g" \
            -e "s|\$${SMTP_PASSWORD}|$$SMTP_PASSWORD|g" \
            -e "s|\$${ALERT_EMAIL}|$$ALERT_EMAIL|g" \
            /etc/alertmanager/alertmanager.yml.template > /tmp/alertmanager.yml && \
        exec /bin/alertmanager --config.file=/tmp/alertmanager.yml --storage.path=/alertmanager
    environment:
      - SMTP_FROM=${SMTP_FROM}
      - SMTP_USERNAME=${SMTP_USERNAME}
      - SMTP_PASSWORD=${SMTP_PASSWORD}
      - ALERT_EMAIL=${ALERT_EMAIL}
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    networks:
      - backend
      - frontend  # Allow localhost access

  # ==========================================================================
  # Grafana Service - Metrics visualization and dashboards
  # ==========================================================================
  grafana:
    image: grafana/grafana:10.2.2
    container_name: rag_grafana
    hostname: grafana

    ports:
      - "3000:3000"

    environment:
      # Admin credentials (configurable via .env)
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}

      # Server configuration
      - GF_SERVER_ROOT_URL=https://localhost/grafana/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true

      # Anonymous access disabled
      - GF_AUTH_ANONYMOUS_ENABLED=false

      # Provisioning
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning

      # Default home dashboard
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/etc/grafana/dashboards/01-system-overview.json

    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/etc/grafana/dashboards:ro
      - grafana_data:/var/lib/grafana

    depends_on:
      prometheus:
        condition: service_healthy
    networks:
      - backend
      - frontend  # Allow localhost access

    restart: unless-stopped

    # Security hardening
    security_opt:
      - no-new-privileges:true

    # Grafana runs as grafana user (472) by default
    user: "472:472"

    # Health check
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=grafana,env=development"

  # ==========================================================================
  # Test Service - Run automated tests
  # ==========================================================================
  # IMPORTANT: This service uses 'test' profile and won't start automatically
  # Usage: docker-compose --profile test up test
  #    or: docker-compose run --rm test
  test:
    profiles: ["test"]  # Only starts when 'test' profile is active
    build:
      context: .
      target: test
    image: personal-rag-system:test
    container_name: rag_test
    hostname: test

    environment:
      - PYTHONUNBUFFERED=1
      - API_URL=http://api:8000
      - LOG_LEVEL=DEBUG
      - COVERAGE_FILE=/tmp/.coverage  # Write coverage to writable tmpfs
      - CHROMA_DIR=/tmp/chroma  # Use writable tmpfs for ChromaDB in tests

    env_file:
      - .env

    volumes:
      # Mount test files
      - ./tests:/workspace/tests:ro
      - ./app:/workspace/app:ro
      - ./pytest.ini:/workspace/pytest.ini:ro

      # Mount eval directory for test outputs
      - ./data/eval:/workspace/data/eval

    depends_on:
      api:
        condition: service_healthy
      redis:
        condition: service_healthy

    # Security hardening
    security_opt:
      - no-new-privileges:true

    cap_drop:
      - ALL

    tmpfs:
      - /tmp:noexec,nosuid,nodev,size=128m

    user: "65532:65532"

    # Override to run specific tests
    # command: ["/opt/venv/bin/python", "-m", "pytest", "-v", "--tb=short"]

    # Don't restart test service
    restart: "no"

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "1"
        labels: "service=test"

# ============================================================================
# Named Volumes - Persistent data storage
# ============================================================================
volumes:
  # Redis data persistence (AOF + RDB)
  redis_data:
    driver: local
    name: rag_redis_data

  # Prometheus time-series data
  prometheus_data:
    driver: local
    name: rag_prometheus_data

  # Grafana dashboards and settings
  grafana_data:
    driver: local
    name: rag_grafana_data

  # Alertmanager data
  alertmanager_data:
    driver: local
    name: rag_alertmanager_data

  # PostgreSQL data
  postgres_data:
    driver: local
    name: rag_postgres_data

  # Caddy data persistence (Certificates)
  caddy_data:
    driver: local
    name: rag_caddy_data

  # Caddy configuration
  caddy_config:
    driver: local
    name: rag_caddy_config

# ============================================================================
# Networks (optional - Docker Compose creates default network)
# ============================================================================
# Uncomment to use custom network with specific configuration
networks:
  frontend:
    driver: bridge
  backend:
    internal: true
    driver: bridge

# ============================================================================
# Secrets - Secure credential injection
# ============================================================================
secrets:
  api_keys:
    file: ./secrets/api_keys
  groq_api_key:
    file: ./secrets/groq_api_key
  postgres_password:
    file: ./secrets/postgres_password
  redis_password:
    file: ./secrets/redis_password



# ============================================================================
# Usage Instructions
# ============================================================================
# Start all services:
#   docker-compose up -d
#
# View logs:
#   docker-compose logs -f
#   docker-compose logs -f api
#   docker-compose logs -f redis
#
# Check health:
#   docker-compose ps
#
# Run tests:
#   docker-compose run --rm test
#
# Stop all services:
#   docker-compose down
#
# Remove all data (WARNING: deletes volumes):
#   docker-compose down -v
#
# Rebuild after code changes:
#   docker-compose up --build -d
# ============================================================================
