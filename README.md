# Personal RAG System

A production-ready Retrieval-Augmented Generation (RAG) system for querying personal documents including resumes, transcripts, certifications, and project documentation. Built with FastAPI, ChromaDB, Ollama, and SentenceTransformers.

## ğŸ—ï¸ Architecture

### System Overview
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                FastAPI Server                    â”‚
â”‚              (app/main.py - 67 lines)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼             â–¼             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Health â”‚   â”‚ Ingest â”‚   â”‚   Chat   â”‚
    â”‚        â”‚   â”‚        â”‚   â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â–¼                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   ChatService   â”‚      â”‚ CertHandler      â”‚
            â”‚   (Core Logic)  â”‚      â”‚ (Cert Queries)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼             â–¼             â–¼             â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Query  â”‚   â”‚ Retrievalâ”‚   â”‚  LLM   â”‚   â”‚Prompt   â”‚
   â”‚ Router â”‚   â”‚ (Chroma) â”‚   â”‚(Ollama)â”‚   â”‚Builder  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

- **`app/api/`** - HTTP API layer
  - `routes/` - Individual endpoint modules (health, ingest, chat, debug)
  - `dependencies.py` - Shared dependencies (auth, service factories)

- **`app/core/`** - Business logic layer
  - `chat_service.py` - Main RAG orchestration (~500 lines)
  - `certification_handler.py` - Certification-specific logic (~450 lines)

- **`app/services/`** - External service integrations
  - `llm.py` - Ollama LLM integration
  - `reranker.py` - Hybrid lexical + semantic reranking

- **`app/query_router/`** - Query analysis and routing
  - `router.py` - Main query router
  - `patterns.py` - Pattern matching utilities
  - `route_helpers/` - Query analyzer and response builder

- **`app/retrieval/`** - Vector database operations
  - `store.py` - ChromaDB integration, embeddings, search

- **`app/prompting/`** - Prompt engineering
  - `builder.py` - Prompt construction and validation
  - `config.py` - Prompt templates and settings
  - `clarification.py` - Ambiguous query handling

- **`app/ingest/`** - Document processing pipeline
  - `processor.py` - Main ingestion orchestrator
  - `discovery.py` - File finding and validation
  - `metadata.py` - YAML front-matter extraction
  - `chunking.py` - Text splitting and section handling

- **`app/certifications/`** - Certification management
  - `registry.py` - Certification metadata registry
  - `models.py` - Certification data models
  - `formatter.py` - Display formatting

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+** (tested with 3.13.1)
- **Ollama** for local LLM hosting
- **Docker & Docker Compose** (optional, for containerized deployment)
- **CUDA-capable GPU** (optional, for faster inference)

### Local Development Setup

1. **Clone and navigate to repository**
   ```bash
   cd RAG_Personal
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment**
   ```bash
   cp .env .env  # Edit with your settings
   ```

   Key settings in `.env`:
   ```bash
   API_KEY=your-secure-api-key-here
   OLLAMA_HOST=http://127.0.0.1:11434
   OLLAMA_MODEL=llama3.2:3b-instruct-q4_K_M
   EMBED_MODEL=BAAI/bge-small-en-v1.5
   CHROMA_DIR=./data/chroma
   DOCS_DIR=./data/mds
   ```

5. **Start Ollama and pull model**
   ```bash
   ollama serve
   ollama pull llama3.2:3b-instruct-q4_K_M
   ```

6. **Prepare your documents**
   - Place markdown files in `./data/mds/`
   - Use YAML front-matter for metadata:
     ```yaml
     ---
     doc_type: resume
     section: experience
     ---
     # Your content here
     ```

7. **Start the server**
   ```bash
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```

8. **Ingest documents** (first time only)
   ```bash
   curl -X POST http://localhost:8000/ingest \
     -H "X-API-Key: your-secure-api-key-here"
   ```

9. **Test the system**
   ```bash
   curl -X POST http://localhost:8000/chat \
     -H "Content-Type: application/json" \
     -H "X-API-Key: your-secure-api-key-here" \
     -d '{"question": "What certifications do I hold?"}'
   ```

### Docker Deployment

1. **Build and start services**
   ```bash
   docker-compose up -d
   ```

2. **Ingest documents**
   ```bash
   docker-compose exec api python -m uvicorn app.main:app
   # Then call /ingest endpoint
   ```

3. **View logs**
   ```bash
   docker-compose logs -f api
   ```

4. **Stop services**
   ```bash
   docker-compose down
   ```

## ğŸ“ Directory Structure

```
RAG_Personal/
â”œâ”€â”€ app/                          # Application code
â”‚   â”œâ”€â”€ api/                      # API layer
â”‚   â”‚   â”œâ”€â”€ routes/              # Endpoint handlers
â”‚   â”‚   â””â”€â”€ dependencies.py      # Shared dependencies
â”‚   â”œâ”€â”€ core/                     # Business logic
â”‚   â”‚   â”œâ”€â”€ chat_service.py      # Main RAG orchestration
â”‚   â”‚   â””â”€â”€ certification_handler.py  # Cert logic
â”‚   â”œâ”€â”€ services/                 # External integrations
â”‚   â”‚   â”œâ”€â”€ llm.py               # Ollama client
â”‚   â”‚   â””â”€â”€ reranker.py          # Result reranking
â”‚   â”œâ”€â”€ query_router/            # Query analysis
â”‚   â”œâ”€â”€ retrieval/               # Vector database
â”‚   â”œâ”€â”€ prompting/               # Prompt engineering
â”‚   â”œâ”€â”€ ingest/                  # Document processing
â”‚   â”œâ”€â”€ certifications/          # Cert management
â”‚   â”œâ”€â”€ middleware/              # HTTP middleware
â”‚   â”œâ”€â”€ monitoring/              # Performance tracking
â”‚   â”œâ”€â”€ main.py                  # FastAPI app setup
â”‚   â”œâ”€â”€ models.py                # Pydantic models
â”‚   â””â”€â”€ settings.py              # Configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mds/                     # Source documents (tracked)
â”‚   â”œâ”€â”€ chroma/                  # Vector database (gitignored)
â”‚   â””â”€â”€ pdfs/                    # Original PDFs (gitignored)
â”œâ”€â”€ tests/                       # Test suite
â”œâ”€â”€ docker-compose.yml           # Container orchestration
â”œâ”€â”€ Dockerfile                   # Container image
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env                         # Environment config (gitignored)
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ latest_analysis.md           # Latest codebase analysis
â””â”€â”€ next_steps.md                # Refactoring action plan
```

## ğŸ”§ Configuration

### Environment Variables

All settings can be configured via `.env` file or environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `API_KEY` | `change-me` | API authentication key |
| `OLLAMA_HOST` | `http://127.0.0.1:11434` | Ollama API endpoint |
| `OLLAMA_MODEL` | `llama3.2:3b-instruct-q4_K_M` | LLM model name |
| `EMBED_MODEL` | `BAAI/bge-small-en-v1.5` | Embedding model |
| `CHROMA_DIR` | `./data/chroma` | Vector database path |
| `DOCS_DIR` | `./data/mds` | Document directory |
| `COLLECTION_NAME` | `personal_rag` | ChromaDB collection |
| `TOP_K` | `5` | Default retrieval count |
| `MAX_DISTANCE` | `0.50` | Max cosine distance |
| `NULL_THRESHOLD` | `0.50` | Grounding threshold |
| `CHUNK_SIZE` | `450` | Characters per chunk |
| `CHUNK_OVERLAP` | `90` | Chunk overlap size |

### Document Metadata

Add YAML front-matter to your markdown files:

```yaml
---
doc_type: resume | certificate | transcript | project
section: experience | education | skills
term_id: spring-2023  # For transcripts
level: undergraduate | graduate  # For transcripts
certification_id: cka  # For certificates
---
```

## ğŸ¯ API Endpoints

### Health Check
```bash
GET /health
```

### Ingest Documents
```bash
POST /ingest
Headers: X-API-Key: your-api-key
```

### Chat (RAG Query)
```bash
POST /chat
Headers:
  Content-Type: application/json
  X-API-Key: your-api-key
Body:
  {
    "question": "What certifications do I hold?",
    "top_k": 5,              # Optional
    "temperature": 0.0,      # Optional
    "doc_type": "certificate" # Optional filter
  }
```

### Debug - Search
```bash
POST /search
Headers:
  Content-Type: application/json
  X-API-Key: your-api-key
Body:
  {
    "question": "kubernetes",
    "k": 10
  }
```

### Debug - Sample Chunks
```bash
GET /sample?n=5
Headers: X-API-Key: your-api-key
```

## ğŸ” Features

### RAG Pipeline
- âœ… **Semantic Search** - BGE v1.5 embeddings with ChromaDB
- âœ… **Metadata Filtering** - Filter by doc_type, term_id, level, etc.
- âœ… **Hybrid Reranking** - Lexical + semantic similarity
- âœ… **Grounding Checks** - Distance thresholds prevent hallucination
- âœ… **Ambiguity Detection** - Asks for clarification on vague queries
- âœ… **Source Citations** - Returns source documents with answers

### Query Routing
- âœ… **Automatic Query Analysis** - Detects technologies, categories, intents
- âœ… **Certificate Detection** - Recognizes cert names and aliases
- âœ… **Parameter Adjustment** - Tunes retrieval based on question type
- âœ… **Confidence Scoring** - Measures routing confidence

### Document Ingestion
- âœ… **Markdown Processing** - Reads .md and .txt files
- âœ… **YAML Metadata Extraction** - Parses front-matter
- âœ… **Smart Chunking** - Section-aware text splitting
- âœ… **Batch Processing** - Efficient large-scale ingestion
- âœ… **Security Checks** - Path traversal prevention

### LLM Integration
- âœ… **Local Hosting** - Ollama for privacy and cost control
- âœ… **Model Flexibility** - Swap models via config
- âœ… **Streaming Support** - For real-time responses (if needed)
- âœ… **Timeout Handling** - Graceful degradation

### Security
- âœ… **API Key Authentication** - Bearer token required
- âœ… **CORS Configuration** - Restricts cross-origin requests
- âœ… **Request Size Limits** - Prevents DoS attacks
- âœ… **Path Traversal Protection** - Secure file access
- âœ… **Docker Security** - Read-only filesystem, dropped capabilities

### Observability
- âœ… **Prometheus Metrics** - Request counts, latencies, chunk retrieval
- âœ… **Structured Logging** - JSON logs with context
- âœ… **Health Checks** - Liveness and readiness probes
- âœ… **Performance Monitoring** - Execution time tracking

## ğŸ§ª Testing

```bash
# Run test suite
python run_tests.py --api-key your-api-key

# Run specific test
python run_tests.py --api-key your-api-key --test health

# Docker testing
docker-compose run test python run_tests.py --api-url http://api:8000
```

## ğŸ“Š Current Status

### âœ… Phase 1 Complete: True RAG Implementation

**Successfully refactored** from hybrid rule-based/RAG system to **pure RAG implementation**!

**What Was Achieved**:
- âœ… Removed **1,116 lines** of hardcoded keyword-based logic
- âœ… Deleted certification registry and handler (no more forced templates)
- âœ… Removed all keyword-based parameter overrides
- âœ… Enabled LLM generation for ALL query types
- âœ… System now uses true retrieval-augmented generation

**Architecture Improvements**:
- âœ… Modular architecture refactoring (970 lines â†’ organized packages)
- âœ… Clean separation of concerns (API, core, services, utilities)
- âœ… ChromaDB vector store integration
- âœ… Ollama LLM integration with streaming
- âœ… Hybrid reranking (lexical + semantic)
- âœ… Query routing with semantic pattern detection
- âœ… Document ingestion pipeline
- âœ… Comprehensive configuration management
- âœ… Docker deployment setup
- âœ… Security hardening (API key, CORS, size limits)
- âœ… Prometheus metrics integration

**Test Results** (2025-11-13):
```
âœ… "Do I have CKA?" â†’ Natural LLM response with correct info
âœ… "When did I earn CKA and when does it expire?" â†’ Multi-part answer
âœ… All queries use semantic search + LLM generation
âœ… No hardcoded templates or keyword forcing
```

### ğŸ¯ System Behavior

**Before Refactoring**:
- âŒ Keyword detection ("do i have", "transcript", etc.)
- âŒ Forced response templates
- âŒ Hardcoded parameter overrides
- âŒ Certification registry with duplicated data
- âŒ ~1,116 lines of anti-RAG code

**After Refactoring** (Current):
- âœ… Pure semantic search for all queries
- âœ… LLM generates all responses from context
- âœ… Natural language flexibility
- âœ… Single source of truth (markdown documents)
- âœ… Clean, maintainable codebase

## ğŸ—ºï¸ Roadmap

### Phase 2: Enhanced Semantic Understanding (Next)
- [ ] Improve system prompt for better focused answers
- [ ] Add query-specific context window (include question in context)
- [ ] Embedding-based query classification
- [ ] LLM-powered intent detection for ambiguous queries
- [ ] Dynamic clarification generation based on available data
- [ ] Context-aware parameter tuning

### Phase 3: Advanced Features
- [ ] Multi-hop reasoning for complex queries
- [ ] Conversational context tracking (chat history)
- [ ] Query reformulation for better retrieval
- [ ] Fact verification and grounding scores
- [ ] Comparative analysis (e.g., "compare my AWS and GCP experience")
- [ ] Support for "what if" and hypothetical queries

### Phase 4: Production Readiness
- [ ] Comprehensive test coverage (unit + integration)
- [ ] Benchmark suite and performance testing
- [ ] Rate limiting and quota management
- [ ] Caching layer for common queries
- [ ] Admin dashboard for monitoring
- [ ] A/B testing framework for prompt improvements

## ğŸ¤ Contributing

This is a personal project, but suggestions are welcome! If you notice issues:

1. Check `latest_analysis.md` for current known issues
2. Review `next_steps.md` for planned fixes
3. Open an issue describing the problem and potential solution

## ğŸ“ License

Private project - not licensed for public use.

## ğŸ”— Resources

- **FastAPI**: https://fastapi.tiangolo.com/
- **ChromaDB**: https://docs.trychroma.com/
- **Ollama**: https://ollama.ai/
- **SentenceTransformers**: https://www.sbert.net/
- **BGE Embeddings**: https://huggingface.co/BAAI/bge-small-en-v1.5

## ğŸ“§ Contact

For questions or issues, refer to the documentation or check the analysis files in the repository.

---

**Status**: âœ… **Stable - True RAG Implementation Complete**
**Version**: 0.4.0
**Last Updated**: 2025-11-13
**Phase 1 Refactoring**: COMPLETE (removed 1,116 lines of anti-RAG code)
