groups:
  - name: rag_system_alerts
    rules:
      # 1. High Error Rate: > 5% 5xx errors over 5m
      # Using http_request_duration_seconds_count (standard metric for total requests)
      - alert: HighErrorRate
        expr: |
          sum(rate(http_request_duration_seconds_count{status=~"5.."}[5m]))
          /
          sum(rate(http_request_duration_seconds_count[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High 5xx error rate detected"
          description: "Over 5% of requests are failing with 5xx errors."

      # 2. High Latency: 99th percentile > 2s over 5m
      - alert: HighLatency
        expr: |
          histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High Latency (p99)"
          description: "99th percentile response time is above 2 seconds."

      # 3. Instance Down: Target down for > 1m
      - alert: InstanceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Instance {{ $labels.instance }} down"
          description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minute."

      # 4. Near OOM (Memory Usage)
      # Assuming process_resident_memory_bytes is available from the Python client
      # Alert if memory usage is absurdly high (e.g. > 1GB for a specific container, adjusting as needed)
      # Since we don't have container memory limits strictly visible here (except redis), this is a basic check.
      - alert: HighMemoryUsage
        expr: process_resident_memory_bytes > 1073741824
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High Memory Usage"
          description: "Instance {{ $labels.instance }} is using more than 1GB of RAM."

      # 5. Redis Down
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis Service Down"
          description: "Redis service has been down for more than 1 minute."

      # 6. Postgres Down
      - alert: PostgresDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL Service Down"
          description: "PostgreSQL service has been down for more than 1 minute."

      # 7. LLMErrorsHigh
      - alert: LLMErrorsHigh
        expr: rate(llm_request_errors_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High LLM Error Rate"
          description: "LLM API error rate is above 5%."

      # 8. DiskSpaceLow
      - alert: DiskSpaceLow
        expr: node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"} * 100 < 15
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low Disk Space"
          description: "Disk space is below 15%."
