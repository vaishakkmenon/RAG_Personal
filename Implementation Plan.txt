— START OF PLAN —

TITLE
Personal-Docs RAG Bot — Master Execution Plan (Text Only)

SCOPE
Build a private Retrieval-Augmented Generation (RAG) chatbot that answers questions strictly from my résumé, transcripts, certification PDFs, and related write-ups. It must abstain with “I don’t know.” when evidence is missing, and cite sources for all answers.

PRINCIPLES

Evidence first: never fabricate; cite sources for each answer.

Reproducible: same inputs → same index → same results.

Minimal, secure, local-first: personal docs never leave my machine unless I explicitly choose to.

Small, iterative steps with a checklist and “definition of done” at each phase.

PHASE 0 — REPO BASELINE
Goal: A clean repo skeleton and configuration with only the essentials.
Inputs: New repo containing only the main Python app files and the scripts I kept.
Actions:
• Create standard folders for app code, scripts, vector DB, and docs (separate raw vs. converted text).
• Add an example environment file listing all configuration keys that the app expects (API key, embedding model name, vector DB path, docs directory, chunking numbers, retrieval thresholds, model name/host).
• Decide whether I will run locally or via containers and document that decision.
Outputs: Folder layout documented; example env file; updated README outline.
Done: Fresh clone + filled env file is sufficient to run the app locally; no legacy files remain.

PHASE 1 — DATA PREP (PDF → CLEAN TEXT/MARKDOWN)
Goal: High-quality, chunk-friendly text derived from personal PDFs.
Inputs: Résumé PDF, transcripts PDFs, certification PDFs or credential text exports, any project summaries.
Actions:
• Place original files in a “raw” area (not tracked by git).
• Convert each PDF to a single text/Markdown file in a “md” area.
• Normalize formatting: consistent headings, lists, and simple tables; remove headers/footers; fix broken line wraps.
• Add a title line per file and clear section headings (Education, GPA, Certifications, Work Experience, Courses, Awards, etc.).
• Redact anything private I do not want indexed (emails, phone numbers, student ID, addresses).
Outputs: One clean text/MD file per original document with clear headings.
Done: Spot-check shows GPA, degree, dates, cert IDs, and course info appear clearly and readably.

PHASE 2 — INGESTION PIPELINE
Goal: Deterministic index build from the converted files.
Inputs: Converted text/MD files; configured embedding model; vector DB path.
Actions:
• Define chunking policy (target chunk size and overlap) and keep it constant.
• Define metadata schema per chunk (doc title, path, section heading, chunk id).
• Define collection naming convention (e.g., “personal_docs”).
• Ensure a single entrypoint can rebuild from scratch (clear then upsert).
• Log counts: files, chunks, and any skipped or empty docs.
Outputs: A populated vector database on disk; an ingestion log with counts and basic stats.
Done: Rebuilding twice produces the same counts; a baseline log is saved.

PHASE 3 — RETRIEVAL SANITY CHECKS
Goal: Confirm the right chunks come back before involving an LLM.
Inputs: A short list of realistic test questions (GPA, degree date, certs and verification links, last three roles, notable projects, key courses).
Actions:
• Run retrieval-only lookups for each question.
• Record top results (document path + section + snippet).
• Adjust only the source text and section headings if the results are off; avoid inflating k unless necessary.
Outputs: A retrieval sanity sheet listing each question and whether top-3 contains the correct chunk.
Done: For all test questions, relevant evidence appears in the top-3 results.

PHASE 4 — RAG CHAIN BEHAVIOR
Goal: End-to-end flow: retrieve → (optional rerank) → answer → cite → abstain when needed.
Inputs: Retrieval working from Phase 3; two operating modes: Generative and Extractive.
Actions:
• Define the standard answer format: concise answer first; bullet citations with filenames/sections.
• Define abstention policy: if evidence is insufficient, respond exactly with “I don’t know.”
• Generative mode: for summaries or open-ended questions; deterministic decoding; calibrated null threshold.
• Extractive mode: for numeric/date/ID facts; strict evidence alignment; stricter null threshold.
• Enforce maximum context size and timeouts; include guardrails against prompt injection in retrieved text.
Outputs: Consistent answer objects containing answer text, citations, and whether it was an abstention.
Done: All test questions return either a correct, cited answer or “I don’t know.” with no hallucinations.

PHASE 5 — CALIBRATION AND TUNING
Goal: Set practical defaults for retrieval and abstention.
Inputs: The same test questions, plus several unanswerable questions that look plausible.
Actions:
• Sweep no-answer thresholds separately for Generative and Extractive modes to minimize false answers while not blocking true ones.
• Keep k small by default; verify reranker weight is helpful but not overpowering.
• Track latency for typical questions and set targets.
Outputs: A short calibration note with the chosen defaults (top-k, distance threshold, rerank weight, null thresholds) and observed median latency.
Done: Defaults selected; calibration note checked into the repo.

PHASE 6 — SELF-EVALUATION SET (OPTIONAL BUT RECOMMENDED)
Goal: A tiny, reproducible evaluation that I can run after changes.
Inputs: A 10–30 item question set in a SQuAD-style or simple JSON format with both answerable and unanswerable items.
Actions:
• Define ground-truth answers for answerable items with references to the specific document/section.
• Include realistic unanswerables to test refusal behavior.
• Run both Generative and Extractive evaluations and capture EM/F1/No-Answer accuracy and latency stats.
Outputs: An evaluation report (CSV or table) and a short “top settings” summary for the README.
Done: A stable, repeatable score exists; regressions are detectable.

PHASE 7 — SECURITY AND PRIVACY
Goal: Keep personal data safe by default.
Inputs: App configuration, logs, and storage locations.
Actions:
• Keep raw PDFs out of version control; commit only converted, redacted text when necessary.
• Require an API key for all endpoints; do not log raw user questions by default.
• Never send documents or embeddings to external services without an explicit decision.
• Document a quick “data wipe and rebuild” procedure.
Outputs: A “Security & Privacy” section in the README stating defaults and trade-offs.
Done: Secrets are not in git history; quick audit shows no personal data leaks in logs.

PHASE 8 — OBSERVABILITY AND RUNBOOK
Goal: Know when it’s healthy and how to debug fast.
Inputs: Application logs and simple health checks.
Actions:
• Provide a health endpoint for the model backend and the API.
• Log retrieval diagnostics: selected doc ids/sections; timing for retrieval, ranking, and generation.
• Write a one-page runbook: common issues and how to resolve them (build failures, index corruption, model not reachable, memory pressure).
Outputs: Health endpoints documented; runbook available; logging levels documented.
Done: A newcomer can diagnose the top 5 issues without help.

PHASE 9 — “ADD A NEW DOCUMENT” SOP
Goal: A repeatable, low-friction way to add or update documents.
Inputs: A new PDF or text file.
Actions:
• Place the file in the raw area; convert to text/MD; verify headings.
• Re-ingest; verify retrieval for a representative question.
• Update the README or a docs ledger with the new document and a sample question it enables.
Outputs: An SOP paragraph in the README; a ledger of documents with dates.
Done: Adding a document takes minutes and produces predictable results.

PHASE 10 — MAINTENANCE AND CHANGE MANAGEMENT
Goal: Keep things stable as parameters evolve.
Inputs: Proposed changes to models, chunking, thresholds, or schema.
Actions:
• Record each change in a CHANGELOG with the rationale.
• Rebuild the index after schema or chunking changes.
• Re-run the self-evaluation and compare against the baseline.
Outputs: Updated CHANGELOG; updated calibration note; updated evaluation table if needed.
Done: Changes are documented; no silent regressions.

PHASE 11 — USER EXPERIENCE (OPTIONAL UI)
Goal: A minimal, clean interface for personal use.
Inputs: Working API.
Actions:
• Provide either a simple CLI or a minimal web page with a single input box and streaming responses.
• Display answer, citations, and elapsed time; show a clear “I don’t know.” for abstentions.
Outputs: A small, responsive interface that respects dark mode and privacy.
Done: Non-technical users (including future me) can ask questions without touching the terminal.

PHASE 12 — DEPLOYMENT CHOICES
Goal: Decide where and how it runs.
Inputs: Hardware availability and privacy constraints.
Actions:
• Default to local execution with GPU if available.
• If remote is required, choose a private environment; ensure encrypted storage and restricted access.
• Document resource expectations (CPU/GPU/RAM) and costs if applicable.
Outputs: A “Deployment” section that states the chosen path and any trade-offs.
Done: The app starts reliably in the chosen environment and passes the sanity tests.

RISK REGISTER (KEEP CURRENT)
• OCR/Extraction quality issues → Mitigation: manual cleanup and headings; test retrieval early.
• Over-broad retrieval (noise in top-k) → Mitigation: improve headings; keep k small; tune reranker weight.
• Hallucinations → Mitigation: strict instructions; enforce abstention; prefer extractive for facts.
• Latency spikes → Mitigation: small k; caching; smaller model; timeouts.
• Privacy leak via logs → Mitigation: scrub logs; avoid storing raw questions by default.

SESSION TEMPLATE (PASTE THIS AT THE START OF EACH CHAT)

Project: Personal-Docs RAG Bot.

Current phase: <state the phase number and name>.

What I need in this session:
• A short checklist for this phase,
• The exact files to touch and what to change,
• The tests/queries I should run,
• The “definition of done” to confirm we can move on.

Constraints: text-only plan is fixed; keep changes minimal; keep privacy in mind.

Output format I want: small steps, then a short validation checklist, then a rollback note if applicable.

— END OF PLAN —